{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ライブラリを指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "from dateutil.parser import parse\n",
    "import json\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, FloatSlider, Checkbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シード値設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWSのデータストレージサービスS3に「sagemaker」という文字列を含めたバケット名のバケットにデータ等を置き、ノートブックを立ち上げる時にそのS3バケット名を指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = 'sagemaker-itoc'\n",
    "s3_prefix = 'itoc'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    " \n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "起動するコンテナイメージを指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3に置いた電力使用実績データを読み取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"s3n://{}/{}\".format(s3_bucket, 'juyo-2017.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATEとTIMEで別のカラムになっているので、一つに統合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATETIME'] = pd.to_datetime(df['DATE']+' '+df[\"TIME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['DATE', 'TIME']).set_index('DATETIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>実績(万kW)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATETIME</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-01 00:00:00</th>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01 01:00:00</th>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01 02:00:00</th>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01 03:00:00</th>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01 04:00:00</th>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     実績(万kW)\n",
       "DATETIME                    \n",
       "2017-04-01 00:00:00      654\n",
       "2017-04-01 01:00:00      660\n",
       "2017-04-01 02:00:00      685\n",
       "2017-04-01 03:00:00      706\n",
       "2017-04-01 04:00:00      696"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2時間の平均になるように変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timeseries = df.shape[1]\n",
    "data_kw = df.resample('2H').sum() / 2\n",
    "timeseries = []\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(data_kw.iloc[:,i], trim='f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1週間分のデータをプロットしてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f43af07f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timeseries[0].loc[\"2017-04-01\":\"2017-04-07\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トレーニングデータとテストデータに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの時間間隔\n",
    "freq = '2H'\n",
    "\n",
    "# どれだけ先まで予測するか、2時間毎なので 7(日) × 12(1日分)\n",
    "prediction_length = 7 * 12\n",
    "\n",
    "# 学習時にどれだけの長さを使うか\n",
    "context_length = 7 * 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングデータとテストデータに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dataset = pd.Timestamp(\"2017-04-01 00:00:00\", freq=freq)\n",
    "end_training = pd.Timestamp(\"2017-12-01 00:00:00\", freq=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_training - 1].tolist()  # We use -1, because pandas indexing includes the upper bound \n",
    "    }\n",
    "    for ts in timeseries\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_windows = 4\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_training + k * prediction_length].tolist()\n",
    "    }\n",
    "    for k in range(1, num_test_windows + 1) \n",
    "    for ts in timeseries\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepAR向けに入力がJSON Lines形式となるように変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.13 ms, sys: 70 µs, total: 5.2 ms\n",
      "Wall time: 5.05 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"train.json\", training_data)\n",
    "write_dicts_to_file(\"test.json\", test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3へデータをコピーするメソッドを定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3://sagemaker-itoc/s3://sagemaker-itoc/itoc/data/train/train.json already exists.\n",
      "Set override to upload anyway.\n",
      "\n",
      "File s3://sagemaker-itoc/s3://sagemaker-itoc/itoc/data/test/test.json already exists.\n",
      "Set override to upload anyway.\n",
      "\n",
      "CPU times: user 23.7 ms, sys: 0 ns, total: 23.7 ms\n",
      "Wall time: 67.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"train.json\", s3_data_path + \"/train/train.json\")\n",
    "copy_to_s3(\"test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2017-04-01 00:00:00\", \"target\": [654, 660, 685, 706, 696, 667, 665, 662, 689, 727, 680, 6...\n"
     ]
    }
   ],
   "source": [
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(s3_data_path + \"/train/train.json\", 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-electricity-demo',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"80\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: deepar-electricity-demo-2019-03-04-06-41-26-931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-04 06:41:27 Starting - Starting the training job...\n",
      "2019-03-04 06:41:28 Starting - Launching requested ML instances......\n",
      "2019-03-04 06:42:31 Starting - Preparing the instances for training...\n",
      "2019-03-04 06:43:22 Downloading - Downloading input data\n",
      "2019-03-04 06:43:22 Training - Downloading the training image...\n",
      "2019-03-04 06:43:55 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'84', u'epochs': u'80', u'time_freq': u'2H', u'context_length': u'84', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'80', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'84', u'time_freq': u'2H', u'context_length': u'84', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[31mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Training set statistics:\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Integer time series\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] number of time series: 1\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] number of observations: 5856\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] mean target length: 5856\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] min/mean/max target: 458.0/669.295081967/1075.0\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] mean abs(target): 669.295081967\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] contains missing values: no\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Small number of time series. Doing 10 number of passes over dataset per epoch.\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Test set statistics:\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Integer time series\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] number of time series: 4\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] number of observations: 25108\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] mean target length: 6277\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] min/mean/max target: 458.0/679.036880675/1075.0\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] mean abs(target): 679.036880675\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] contains missing values: no\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] nvidia-smi took: 0.0252048969269 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:57 INFO 140211577685824] Create Store: local\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 1663.2258892059326, \"sum\": 1663.2258892059326, \"min\": 1663.2258892059326}}, \"EndTime\": 1551681839.191876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681837.527633}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:43:59 INFO 140211577685824] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 2403.502941131592, \"sum\": 2403.502941131592, \"min\": 2403.502941131592}}, \"EndTime\": 1551681839.931261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681839.191954}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:00 INFO 140211577685824] Epoch[0] Batch[0] avg_epoch_loss=8.786828\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:01 INFO 140211577685824] Epoch[0] Batch[5] avg_epoch_loss=8.031248\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:01 INFO 140211577685824] Epoch[0] Batch [5]#011Speed: 300.20 samples/sec#011loss=8.031248\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:02 INFO 140211577685824] Epoch[0] Batch[10] avg_epoch_loss=7.662872\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:02 INFO 140211577685824] Epoch[0] Batch [10]#011Speed: 293.94 samples/sec#011loss=7.220821\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:03 INFO 140211577685824] processed a total of 713 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 80, \"sum\": 80.0, \"min\": 80}, \"update.time\": {\"count\": 1, \"max\": 3195.794105529785, \"sum\": 3195.794105529785, \"min\": 3195.794105529785}}, \"EndTime\": 1551681843.127248, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681839.931356}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:03 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=223.097015843 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:03 INFO 140211577685824] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:03 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:03 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_7a296969-17b2-4a87-8521-6853adb874ed-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.005022048950195, \"sum\": 59.005022048950195, \"min\": 59.005022048950195}}, \"EndTime\": 1551681843.186804, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681843.127331}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:03 INFO 140211577685824] Epoch[1] Batch[0] avg_epoch_loss=7.045597\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:04 INFO 140211577685824] Epoch[1] Batch[5] avg_epoch_loss=6.944698\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:04 INFO 140211577685824] Epoch[1] Batch [5]#011Speed: 300.63 samples/sec#011loss=6.944698\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] Epoch[1] Batch[10] avg_epoch_loss=6.864488\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] Epoch[1] Batch [10]#011Speed: 296.56 samples/sec#011loss=6.768236\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] processed a total of 659 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2619.8480129241943, \"sum\": 2619.8480129241943, \"min\": 2619.8480129241943}}, \"EndTime\": 1551681845.806808, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681843.186885}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=251.529017444 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:05 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_aabb4110-fd13-436b-9477-2cb486827a85-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 95.91102600097656, \"sum\": 95.91102600097656, \"min\": 95.91102600097656}}, \"EndTime\": 1551681845.903238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681845.806892}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:06 INFO 140211577685824] Epoch[2] Batch[0] avg_epoch_loss=6.611588\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:07 INFO 140211577685824] Epoch[2] Batch[5] avg_epoch_loss=6.492088\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:07 INFO 140211577685824] Epoch[2] Batch [5]#011Speed: 254.50 samples/sec#011loss=6.492088\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:08 INFO 140211577685824] processed a total of 635 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2638.3440494537354, \"sum\": 2638.3440494537354, \"min\": 2638.3440494537354}}, \"EndTime\": 1551681848.541728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681845.903317}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:08 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=240.670527504 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:08 INFO 140211577685824] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:08 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:08 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_7b024509-4c06-46b5-9434-9d3e0aaee49b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 60.74190139770508, \"sum\": 60.74190139770508, \"min\": 60.74190139770508}}, \"EndTime\": 1551681848.602985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681848.541805}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:09 INFO 140211577685824] Epoch[3] Batch[0] avg_epoch_loss=6.264833\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:10 INFO 140211577685824] Epoch[3] Batch[5] avg_epoch_loss=6.196946\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:10 INFO 140211577685824] Epoch[3] Batch [5]#011Speed: 307.27 samples/sec#011loss=6.196946\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] Epoch[3] Batch[10] avg_epoch_loss=6.175788\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] Epoch[3] Batch [10]#011Speed: 286.56 samples/sec#011loss=6.150399\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] processed a total of 671 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2641.9339179992676, \"sum\": 2641.9339179992676, \"min\": 2641.9339179992676}}, \"EndTime\": 1551681851.245082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681848.603076}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=253.968765315 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_aa0d6ed8-2036-4103-8242-3605d6e631ad-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.82007217407227, \"sum\": 67.82007217407227, \"min\": 67.82007217407227}}, \"EndTime\": 1551681851.313355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681851.245164}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:11 INFO 140211577685824] Epoch[4] Batch[0] avg_epoch_loss=6.114649\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:12 INFO 140211577685824] Epoch[4] Batch[5] avg_epoch_loss=6.089693\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:12 INFO 140211577685824] Epoch[4] Batch [5]#011Speed: 299.44 samples/sec#011loss=6.089693\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:13 INFO 140211577685824] Epoch[4] Batch[10] avg_epoch_loss=6.106825\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:13 INFO 140211577685824] Epoch[4] Batch [10]#011Speed: 296.77 samples/sec#011loss=6.127384\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:13 INFO 140211577685824] processed a total of 646 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2597.6059436798096, \"sum\": 2597.6059436798096, \"min\": 2597.6059436798096}}, \"EndTime\": 1551681853.911112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681851.313436}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:13 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=248.678364879 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:13 INFO 140211577685824] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:13 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:14 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_4b213ad2-7850-4095-bf0d-fa38fcb48b97-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 89.96391296386719, \"sum\": 89.96391296386719, \"min\": 89.96391296386719}}, \"EndTime\": 1551681854.001543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681853.911197}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:14 INFO 140211577685824] Epoch[5] Batch[0] avg_epoch_loss=5.991566\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:15 INFO 140211577685824] Epoch[5] Batch[5] avg_epoch_loss=5.908933\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:15 INFO 140211577685824] Epoch[5] Batch [5]#011Speed: 302.15 samples/sec#011loss=5.908933\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:44:16 INFO 140211577685824] processed a total of 620 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2355.215072631836, \"sum\": 2355.215072631836, \"min\": 2355.215072631836}}, \"EndTime\": 1551681856.356896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681854.001618}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:16 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=263.231528322 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:16 INFO 140211577685824] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:16 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:16 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_b99cb250-8541-49df-8254-cddca00ecc02-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 90.82317352294922, \"sum\": 90.82317352294922, \"min\": 90.82317352294922}}, \"EndTime\": 1551681856.448191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681856.356982}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:16 INFO 140211577685824] Epoch[6] Batch[0] avg_epoch_loss=5.790461\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:17 INFO 140211577685824] Epoch[6] Batch[5] avg_epoch_loss=5.761526\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:17 INFO 140211577685824] Epoch[6] Batch [5]#011Speed: 297.34 samples/sec#011loss=5.761526\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:18 INFO 140211577685824] processed a total of 624 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2377.4349689483643, \"sum\": 2377.4349689483643, \"min\": 2377.4349689483643}}, \"EndTime\": 1551681858.82579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681856.448285}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:18 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=262.453376381 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:18 INFO 140211577685824] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:18 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:18 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_70f41e93-ed1d-44dd-9985-34320ec240ed-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 58.6700439453125, \"sum\": 58.6700439453125, \"min\": 58.6700439453125}}, \"EndTime\": 1551681858.88498, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681858.825878}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:19 INFO 140211577685824] Epoch[7] Batch[0] avg_epoch_loss=5.597185\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:20 INFO 140211577685824] Epoch[7] Batch[5] avg_epoch_loss=5.550028\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:20 INFO 140211577685824] Epoch[7] Batch [5]#011Speed: 304.30 samples/sec#011loss=5.550028\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] Epoch[7] Batch[10] avg_epoch_loss=5.480090\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] Epoch[7] Batch [10]#011Speed: 280.15 samples/sec#011loss=5.396164\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] processed a total of 643 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2661.163091659546, \"sum\": 2661.163091659546, \"min\": 2661.163091659546}}, \"EndTime\": 1551681861.546284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681858.885053}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=241.612524796 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:21 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_d1f0f12b-67db-495d-a48a-eedf76e57d1d-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 89.06793594360352, \"sum\": 89.06793594360352, \"min\": 89.06793594360352}}, \"EndTime\": 1551681861.635809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681861.546365}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:22 INFO 140211577685824] Epoch[8] Batch[0] avg_epoch_loss=5.475744\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:23 INFO 140211577685824] Epoch[8] Batch[5] avg_epoch_loss=5.404033\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:23 INFO 140211577685824] Epoch[8] Batch [5]#011Speed: 297.85 samples/sec#011loss=5.404033\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:24 INFO 140211577685824] processed a total of 638 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2412.9788875579834, \"sum\": 2412.9788875579834, \"min\": 2412.9788875579834}}, \"EndTime\": 1551681864.048938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681861.63589}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:24 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=264.389419349 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:24 INFO 140211577685824] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:24 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:24 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_809be8cb-9d56-46f8-9552-01b60bb50eee-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 64.61882591247559, \"sum\": 64.61882591247559, \"min\": 64.61882591247559}}, \"EndTime\": 1551681864.114011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681864.049024}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:24 INFO 140211577685824] Epoch[9] Batch[0] avg_epoch_loss=5.329224\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:25 INFO 140211577685824] Epoch[9] Batch[5] avg_epoch_loss=5.254335\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:25 INFO 140211577685824] Epoch[9] Batch [5]#011Speed: 299.25 samples/sec#011loss=5.254335\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] Epoch[9] Batch[10] avg_epoch_loss=5.237763\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] Epoch[9] Batch [10]#011Speed: 294.62 samples/sec#011loss=5.217878\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] processed a total of 658 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2613.866090774536, \"sum\": 2613.866090774536, \"min\": 2613.866090774536}}, \"EndTime\": 1551681866.728026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681864.114092}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=251.722662639 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:26 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_be6beba8-9dcf-4a9a-9d2b-ffa65a6cf407-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.51978874206543, \"sum\": 62.51978874206543, \"min\": 62.51978874206543}}, \"EndTime\": 1551681866.790994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681866.728107}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:27 INFO 140211577685824] Epoch[10] Batch[0] avg_epoch_loss=5.184309\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:28 INFO 140211577685824] Epoch[10] Batch[5] avg_epoch_loss=5.205097\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:28 INFO 140211577685824] Epoch[10] Batch [5]#011Speed: 299.34 samples/sec#011loss=5.205097\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:29 INFO 140211577685824] processed a total of 578 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2366.2869930267334, \"sum\": 2366.2869930267334, \"min\": 2366.2869930267334}}, \"EndTime\": 1551681869.157431, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681866.791084}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:29 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=244.251445903 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:29 INFO 140211577685824] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:29 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:29 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_0cfa7ab9-0c7a-454b-952a-ede5226d4b28-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.99187850952148, \"sum\": 65.99187850952148, \"min\": 65.99187850952148}}, \"EndTime\": 1551681869.223893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681869.157517}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:29 INFO 140211577685824] Epoch[11] Batch[0] avg_epoch_loss=5.449758\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:30 INFO 140211577685824] Epoch[11] Batch[5] avg_epoch_loss=5.301665\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:30 INFO 140211577685824] Epoch[11] Batch [5]#011Speed: 293.86 samples/sec#011loss=5.301665\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:31 INFO 140211577685824] Epoch[11] Batch[10] avg_epoch_loss=5.259374\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:31 INFO 140211577685824] Epoch[11] Batch [10]#011Speed: 288.07 samples/sec#011loss=5.208623\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:31 INFO 140211577685824] processed a total of 665 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2681.4560890197754, \"sum\": 2681.4560890197754, \"min\": 2681.4560890197754}}, \"EndTime\": 1551681871.905505, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681869.223979}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:31 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=247.987943848 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:31 INFO 140211577685824] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:31 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:32 INFO 140211577685824] Epoch[12] Batch[0] avg_epoch_loss=5.162909\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:33 INFO 140211577685824] Epoch[12] Batch[5] avg_epoch_loss=5.123576\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:33 INFO 140211577685824] Epoch[12] Batch [5]#011Speed: 302.32 samples/sec#011loss=5.123576\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] Epoch[12] Batch[10] avg_epoch_loss=5.126592\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] Epoch[12] Batch [10]#011Speed: 293.85 samples/sec#011loss=5.130212\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] processed a total of 657 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2621.2399005889893, \"sum\": 2621.2399005889893, \"min\": 2621.2399005889893}}, \"EndTime\": 1551681874.527156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681871.905589}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=250.632774287 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:34 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_06054570-a363-4493-9c59-d2ce1fa51c0c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 90.09718894958496, \"sum\": 90.09718894958496, \"min\": 90.09718894958496}}, \"EndTime\": 1551681874.617707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681874.527239}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:35 INFO 140211577685824] Epoch[13] Batch[0] avg_epoch_loss=5.385502\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:44:36 INFO 140211577685824] Epoch[13] Batch[5] avg_epoch_loss=5.173184\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:36 INFO 140211577685824] Epoch[13] Batch [5]#011Speed: 290.97 samples/sec#011loss=5.173184\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:37 INFO 140211577685824] processed a total of 615 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2470.5309867858887, \"sum\": 2470.5309867858887, \"min\": 2470.5309867858887}}, \"EndTime\": 1551681877.08838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681874.617784}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:37 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=248.921559942 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:37 INFO 140211577685824] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:37 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:37 INFO 140211577685824] Epoch[14] Batch[0] avg_epoch_loss=5.115131\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:38 INFO 140211577685824] Epoch[14] Batch[5] avg_epoch_loss=5.073517\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:38 INFO 140211577685824] Epoch[14] Batch [5]#011Speed: 302.27 samples/sec#011loss=5.073517\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] Epoch[14] Batch[10] avg_epoch_loss=5.065658\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] Epoch[14] Batch [10]#011Speed: 295.70 samples/sec#011loss=5.056226\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] processed a total of 681 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2626.1470317840576, \"sum\": 2626.1470317840576, \"min\": 2626.1470317840576}}, \"EndTime\": 1551681879.715021, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681877.088466}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=259.299369781 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:39 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_4c935572-790f-4c64-8347-0066d83abc2c-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 86.09986305236816, \"sum\": 86.09986305236816, \"min\": 86.09986305236816}}, \"EndTime\": 1551681879.801618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681879.71514}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:40 INFO 140211577685824] Epoch[15] Batch[0] avg_epoch_loss=5.106056\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:41 INFO 140211577685824] Epoch[15] Batch[5] avg_epoch_loss=5.048882\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:41 INFO 140211577685824] Epoch[15] Batch [5]#011Speed: 297.09 samples/sec#011loss=5.048882\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:42 INFO 140211577685824] processed a total of 618 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2403.3429622650146, \"sum\": 2403.3429622650146, \"min\": 2403.3429622650146}}, \"EndTime\": 1551681882.205102, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681879.801698}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:42 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=257.12789963 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:42 INFO 140211577685824] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:42 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:42 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_12299edd-6bdf-44c0-82ae-d8fa1e2b39c6-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.79894638061523, \"sum\": 69.79894638061523, \"min\": 69.79894638061523}}, \"EndTime\": 1551681882.275376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681882.205191}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:42 INFO 140211577685824] Epoch[16] Batch[0] avg_epoch_loss=5.051577\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:43 INFO 140211577685824] Epoch[16] Batch[5] avg_epoch_loss=5.002583\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:43 INFO 140211577685824] Epoch[16] Batch [5]#011Speed: 300.47 samples/sec#011loss=5.002583\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] Epoch[16] Batch[10] avg_epoch_loss=4.976632\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] Epoch[16] Batch [10]#011Speed: 292.33 samples/sec#011loss=4.945490\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] processed a total of 663 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2638.239860534668, \"sum\": 2638.239860534668, \"min\": 2638.239860534668}}, \"EndTime\": 1551681884.913752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681882.275451}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=251.29228566 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:44 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_9eb51abd-e790-4b67-925e-b70db74664a5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 65.05298614501953, \"sum\": 65.05298614501953, \"min\": 65.05298614501953}}, \"EndTime\": 1551681884.979255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681884.913835}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:45 INFO 140211577685824] Epoch[17] Batch[0] avg_epoch_loss=5.039799\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:46 INFO 140211577685824] Epoch[17] Batch[5] avg_epoch_loss=5.000994\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:46 INFO 140211577685824] Epoch[17] Batch [5]#011Speed: 287.93 samples/sec#011loss=5.000994\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:47 INFO 140211577685824] processed a total of 623 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2417.119026184082, \"sum\": 2417.119026184082, \"min\": 2417.119026184082}}, \"EndTime\": 1551681887.39651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681884.97933}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:47 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=257.73100297 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:47 INFO 140211577685824] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:47 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:47 INFO 140211577685824] Epoch[18] Batch[0] avg_epoch_loss=4.943746\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:48 INFO 140211577685824] Epoch[18] Batch[5] avg_epoch_loss=4.949770\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:48 INFO 140211577685824] Epoch[18] Batch [5]#011Speed: 295.44 samples/sec#011loss=4.949770\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:49 INFO 140211577685824] processed a total of 620 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2390.8870220184326, \"sum\": 2390.8870220184326, \"min\": 2390.8870220184326}}, \"EndTime\": 1551681889.787821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681887.396598}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:49 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=259.305079888 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:49 INFO 140211577685824] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:49 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:49 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_4074c279-df00-41e4-a333-e654d4d0df6e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 56.5190315246582, \"sum\": 56.5190315246582, \"min\": 56.5190315246582}}, \"EndTime\": 1551681889.844834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681889.787898}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:50 INFO 140211577685824] Epoch[19] Batch[0] avg_epoch_loss=4.931748\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:51 INFO 140211577685824] Epoch[19] Batch[5] avg_epoch_loss=4.914648\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:51 INFO 140211577685824] Epoch[19] Batch [5]#011Speed: 293.24 samples/sec#011loss=4.914648\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:52 INFO 140211577685824] processed a total of 628 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2414.484977722168, \"sum\": 2414.484977722168, \"min\": 2414.484977722168}}, \"EndTime\": 1551681892.259468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681889.844913}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:52 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=260.083495752 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:52 INFO 140211577685824] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:52 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:52 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_836c4dd2-467c-4488-8cfe-00ea9e3df0f4-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 76.37596130371094, \"sum\": 76.37596130371094, \"min\": 76.37596130371094}}, \"EndTime\": 1551681892.336291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681892.259549}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:52 INFO 140211577685824] Epoch[20] Batch[0] avg_epoch_loss=4.951943\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:53 INFO 140211577685824] Epoch[20] Batch[5] avg_epoch_loss=4.941542\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:53 INFO 140211577685824] Epoch[20] Batch [5]#011Speed: 298.93 samples/sec#011loss=4.941542\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:54 INFO 140211577685824] Epoch[20] Batch[10] avg_epoch_loss=4.915936\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:54 INFO 140211577685824] Epoch[20] Batch [10]#011Speed: 298.03 samples/sec#011loss=4.885209\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:54 INFO 140211577685824] processed a total of 696 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2627.520799636841, \"sum\": 2627.520799636841, \"min\": 2627.520799636841}}, \"EndTime\": 1551681894.963962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681892.33637}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:54 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=264.876057627 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:54 INFO 140211577685824] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:54 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:55 INFO 140211577685824] Epoch[21] Batch[0] avg_epoch_loss=4.918647\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:44:56 INFO 140211577685824] Epoch[21] Batch[5] avg_epoch_loss=4.888950\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:56 INFO 140211577685824] Epoch[21] Batch [5]#011Speed: 298.62 samples/sec#011loss=4.888950\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] Epoch[21] Batch[10] avg_epoch_loss=4.872114\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] Epoch[21] Batch [10]#011Speed: 294.80 samples/sec#011loss=4.851910\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] processed a total of 708 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2912.8379821777344, \"sum\": 2912.8379821777344, \"min\": 2912.8379821777344}}, \"EndTime\": 1551681897.877205, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681894.964045}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=243.051915843 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:57 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_f48cfc12-e943-43af-8003-4261e7829b1d-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 88.90199661254883, \"sum\": 88.90199661254883, \"min\": 88.90199661254883}}, \"EndTime\": 1551681897.966547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681897.877286}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:58 INFO 140211577685824] Epoch[22] Batch[0] avg_epoch_loss=4.797623\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:59 INFO 140211577685824] Epoch[22] Batch[5] avg_epoch_loss=4.832071\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:44:59 INFO 140211577685824] Epoch[22] Batch [5]#011Speed: 295.16 samples/sec#011loss=4.832071\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] Epoch[22] Batch[10] avg_epoch_loss=4.834109\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] Epoch[22] Batch [10]#011Speed: 298.62 samples/sec#011loss=4.836555\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] processed a total of 650 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2615.027904510498, \"sum\": 2615.027904510498, \"min\": 2615.027904510498}}, \"EndTime\": 1551681900.581725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681897.966627}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=248.551710708 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:00 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_b63b6829-904d-4233-a4eb-3395c1e10eee-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 89.2629623413086, \"sum\": 89.2629623413086, \"min\": 89.2629623413086}}, \"EndTime\": 1551681900.671444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681900.581806}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:01 INFO 140211577685824] Epoch[23] Batch[0] avg_epoch_loss=4.859978\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:02 INFO 140211577685824] Epoch[23] Batch[5] avg_epoch_loss=4.818893\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:02 INFO 140211577685824] Epoch[23] Batch [5]#011Speed: 294.56 samples/sec#011loss=4.818893\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:03 INFO 140211577685824] processed a total of 638 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2490.9439086914062, \"sum\": 2490.9439086914062, \"min\": 2490.9439086914062}}, \"EndTime\": 1551681903.162523, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681900.671517}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:03 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=256.114642814 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:03 INFO 140211577685824] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:03 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:03 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_ed036b1d-d6b5-4bd1-80d1-7f57f247abcd-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.767961502075195, \"sum\": 59.767961502075195, \"min\": 59.767961502075195}}, \"EndTime\": 1551681903.222812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681903.162611}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:03 INFO 140211577685824] Epoch[24] Batch[0] avg_epoch_loss=4.799906\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:04 INFO 140211577685824] Epoch[24] Batch[5] avg_epoch_loss=4.794616\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:04 INFO 140211577685824] Epoch[24] Batch [5]#011Speed: 306.17 samples/sec#011loss=4.794616\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:05 INFO 140211577685824] processed a total of 622 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2361.970901489258, \"sum\": 2361.970901489258, \"min\": 2361.970901489258}}, \"EndTime\": 1551681905.584929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681903.222884}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:05 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=263.324674601 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:05 INFO 140211577685824] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:05 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:05 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_d7e2ba2a-f7a0-45e9-a57e-dec31f353c1e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.85799026489258, \"sum\": 57.85799026489258, \"min\": 57.85799026489258}}, \"EndTime\": 1551681905.643306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681905.585016}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:06 INFO 140211577685824] Epoch[25] Batch[0] avg_epoch_loss=4.915420\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:07 INFO 140211577685824] Epoch[25] Batch[5] avg_epoch_loss=4.788892\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:07 INFO 140211577685824] Epoch[25] Batch [5]#011Speed: 289.37 samples/sec#011loss=4.788892\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] Epoch[25] Batch[10] avg_epoch_loss=4.788167\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] Epoch[25] Batch [10]#011Speed: 289.82 samples/sec#011loss=4.787297\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] processed a total of 654 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2662.9011631011963, \"sum\": 2662.9011631011963, \"min\": 2662.9011631011963}}, \"EndTime\": 1551681908.306355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681905.643384}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=245.585100705 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_6c31c37a-db1a-4186-8644-5706dfc5abb1-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.08785820007324, \"sum\": 74.08785820007324, \"min\": 74.08785820007324}}, \"EndTime\": 1551681908.380897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681908.306439}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:08 INFO 140211577685824] Epoch[26] Batch[0] avg_epoch_loss=4.642537\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:09 INFO 140211577685824] Epoch[26] Batch[5] avg_epoch_loss=4.771792\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:09 INFO 140211577685824] Epoch[26] Batch [5]#011Speed: 299.95 samples/sec#011loss=4.771792\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:10 INFO 140211577685824] processed a total of 614 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2389.369010925293, \"sum\": 2389.369010925293, \"min\": 2389.369010925293}}, \"EndTime\": 1551681910.77042, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681908.380979}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:10 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=256.957738064 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:10 INFO 140211577685824] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:10 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:10 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_43c5f3ce-30f4-4f3c-a7f8-988c4c384a9b-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 56.47587776184082, \"sum\": 56.47587776184082, \"min\": 56.47587776184082}}, \"EndTime\": 1551681910.827359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681910.770506}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:11 INFO 140211577685824] Epoch[27] Batch[0] avg_epoch_loss=5.078449\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:12 INFO 140211577685824] Epoch[27] Batch[5] avg_epoch_loss=4.979565\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:12 INFO 140211577685824] Epoch[27] Batch [5]#011Speed: 294.45 samples/sec#011loss=4.979565\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:13 INFO 140211577685824] processed a total of 632 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2404.676914215088, \"sum\": 2404.676914215088, \"min\": 2404.676914215088}}, \"EndTime\": 1551681913.23218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681910.827434}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:13 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=262.80704721 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:13 INFO 140211577685824] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:13 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:13 INFO 140211577685824] Epoch[28] Batch[0] avg_epoch_loss=4.953817\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:14 INFO 140211577685824] Epoch[28] Batch[5] avg_epoch_loss=4.854667\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:14 INFO 140211577685824] Epoch[28] Batch [5]#011Speed: 301.97 samples/sec#011loss=4.854667\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:45:15 INFO 140211577685824] Epoch[28] Batch[10] avg_epoch_loss=4.815434\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:15 INFO 140211577685824] Epoch[28] Batch [10]#011Speed: 291.11 samples/sec#011loss=4.768354\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:15 INFO 140211577685824] processed a total of 656 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2621.401071548462, \"sum\": 2621.401071548462, \"min\": 2621.401071548462}}, \"EndTime\": 1551681915.85401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681913.232267}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:15 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=250.235931011 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:15 INFO 140211577685824] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:15 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:16 INFO 140211577685824] Epoch[29] Batch[0] avg_epoch_loss=4.721567\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:17 INFO 140211577685824] Epoch[29] Batch[5] avg_epoch_loss=4.714462\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:17 INFO 140211577685824] Epoch[29] Batch [5]#011Speed: 299.54 samples/sec#011loss=4.714462\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:18 INFO 140211577685824] processed a total of 629 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2440.1488304138184, \"sum\": 2440.1488304138184, \"min\": 2440.1488304138184}}, \"EndTime\": 1551681918.294568, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681915.854092}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:18 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=257.757512163 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:18 INFO 140211577685824] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:18 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:18 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_b4434dde-91b5-46f4-bbe6-9c7b3e03a5f6-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.37316131591797, \"sum\": 62.37316131591797, \"min\": 62.37316131591797}}, \"EndTime\": 1551681918.357404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681918.294656}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:18 INFO 140211577685824] Epoch[30] Batch[0] avg_epoch_loss=4.645270\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:19 INFO 140211577685824] Epoch[30] Batch[5] avg_epoch_loss=4.708207\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:19 INFO 140211577685824] Epoch[30] Batch [5]#011Speed: 303.30 samples/sec#011loss=4.708207\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] Epoch[30] Batch[10] avg_epoch_loss=4.675861\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] Epoch[30] Batch [10]#011Speed: 298.28 samples/sec#011loss=4.637045\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] processed a total of 653 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2579.0441036224365, \"sum\": 2579.0441036224365, \"min\": 2579.0441036224365}}, \"EndTime\": 1551681920.936593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681918.357485}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=253.182717894 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:20 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_1b1c2043-fde5-4c52-a463-78be8c210d3e-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.09409713745117, \"sum\": 57.09409713745117, \"min\": 57.09409713745117}}, \"EndTime\": 1551681920.994224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681920.936675}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:21 INFO 140211577685824] Epoch[31] Batch[0] avg_epoch_loss=4.679484\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:22 INFO 140211577685824] Epoch[31] Batch[5] avg_epoch_loss=4.698262\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:22 INFO 140211577685824] Epoch[31] Batch [5]#011Speed: 292.45 samples/sec#011loss=4.698262\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:23 INFO 140211577685824] Epoch[31] Batch[10] avg_epoch_loss=4.723772\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:23 INFO 140211577685824] Epoch[31] Batch [10]#011Speed: 295.44 samples/sec#011loss=4.754385\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:23 INFO 140211577685824] processed a total of 646 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2635.9570026397705, \"sum\": 2635.9570026397705, \"min\": 2635.9570026397705}}, \"EndTime\": 1551681923.63033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681920.994305}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:23 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=245.060756793 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:23 INFO 140211577685824] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:23 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:24 INFO 140211577685824] Epoch[32] Batch[0] avg_epoch_loss=4.704575\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:25 INFO 140211577685824] Epoch[32] Batch[5] avg_epoch_loss=4.658741\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:25 INFO 140211577685824] Epoch[32] Batch [5]#011Speed: 305.44 samples/sec#011loss=4.658741\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:26 INFO 140211577685824] processed a total of 631 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2435.2710247039795, \"sum\": 2435.2710247039795, \"min\": 2435.2710247039795}}, \"EndTime\": 1551681926.066006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681923.630412}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:26 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=259.09491276 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:26 INFO 140211577685824] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:26 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:26 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_edd99ea8-8b01-42e1-838b-c8dd721fb7b5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 90.95311164855957, \"sum\": 90.95311164855957, \"min\": 90.95311164855957}}, \"EndTime\": 1551681926.157433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681926.066093}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:26 INFO 140211577685824] Epoch[33] Batch[0] avg_epoch_loss=4.606475\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:27 INFO 140211577685824] Epoch[33] Batch[5] avg_epoch_loss=4.638092\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:27 INFO 140211577685824] Epoch[33] Batch [5]#011Speed: 302.70 samples/sec#011loss=4.638092\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:28 INFO 140211577685824] processed a total of 617 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2440.9780502319336, \"sum\": 2440.9780502319336, \"min\": 2440.9780502319336}}, \"EndTime\": 1551681928.598555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681926.15751}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:28 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=252.754374685 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:28 INFO 140211577685824] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:28 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:28 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_490636fb-c1b8-4a0f-8f08-9c46b8c7f9fa-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 63.26103210449219, \"sum\": 63.26103210449219, \"min\": 63.26103210449219}}, \"EndTime\": 1551681928.662296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681928.598641}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:29 INFO 140211577685824] Epoch[34] Batch[0] avg_epoch_loss=4.589427\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:30 INFO 140211577685824] Epoch[34] Batch[5] avg_epoch_loss=4.590871\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:30 INFO 140211577685824] Epoch[34] Batch [5]#011Speed: 299.40 samples/sec#011loss=4.590871\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:31 INFO 140211577685824] processed a total of 606 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2384.1488361358643, \"sum\": 2384.1488361358643, \"min\": 2384.1488361358643}}, \"EndTime\": 1551681931.04658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681928.662369}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:31 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=254.165189539 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:31 INFO 140211577685824] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:31 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:31 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_dbd952f6-d79d-421f-adb7-44f8076f9a52-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 88.51814270019531, \"sum\": 88.51814270019531, \"min\": 88.51814270019531}}, \"EndTime\": 1551681931.135561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681931.046667}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:31 INFO 140211577685824] Epoch[35] Batch[0] avg_epoch_loss=4.836577\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:32 INFO 140211577685824] Epoch[35] Batch[5] avg_epoch_loss=4.655456\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:32 INFO 140211577685824] Epoch[35] Batch [5]#011Speed: 294.21 samples/sec#011loss=4.655456\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:33 INFO 140211577685824] processed a total of 634 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2396.4059352874756, \"sum\": 2396.4059352874756, \"min\": 2396.4059352874756}}, \"EndTime\": 1551681933.532116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681931.135642}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:33 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=264.548591262 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:33 INFO 140211577685824] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:33 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:33 INFO 140211577685824] Epoch[36] Batch[0] avg_epoch_loss=4.529815\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:35 INFO 140211577685824] Epoch[36] Batch[5] avg_epoch_loss=4.588303\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:35 INFO 140211577685824] Epoch[36] Batch [5]#011Speed: 296.87 samples/sec#011loss=4.588303\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:45:35 INFO 140211577685824] processed a total of 630 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2405.8542251586914, \"sum\": 2405.8542251586914, \"min\": 2405.8542251586914}}, \"EndTime\": 1551681935.938385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681933.532204}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:35 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=261.847447375 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:35 INFO 140211577685824] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:35 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:36 INFO 140211577685824] Epoch[37] Batch[0] avg_epoch_loss=4.591022\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:37 INFO 140211577685824] Epoch[37] Batch[5] avg_epoch_loss=4.565721\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:37 INFO 140211577685824] Epoch[37] Batch [5]#011Speed: 293.55 samples/sec#011loss=4.565721\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:38 INFO 140211577685824] processed a total of 631 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2401.094913482666, \"sum\": 2401.094913482666, \"min\": 2401.094913482666}}, \"EndTime\": 1551681938.339897, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681935.938472}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:38 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=262.783180523 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:38 INFO 140211577685824] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:38 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:38 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_d4477636-286e-4fdb-adee-dc3a7b90c774-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.12684440612793, \"sum\": 69.12684440612793, \"min\": 69.12684440612793}}, \"EndTime\": 1551681938.409486, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681938.339981}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:38 INFO 140211577685824] Epoch[38] Batch[0] avg_epoch_loss=4.611228\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:39 INFO 140211577685824] Epoch[38] Batch[5] avg_epoch_loss=4.586904\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:39 INFO 140211577685824] Epoch[38] Batch [5]#011Speed: 306.52 samples/sec#011loss=4.586904\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] Epoch[38] Batch[10] avg_epoch_loss=4.536733\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] Epoch[38] Batch [10]#011Speed: 292.54 samples/sec#011loss=4.476529\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] processed a total of 645 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2601.396083831787, \"sum\": 2601.396083831787, \"min\": 2601.396083831787}}, \"EndTime\": 1551681941.01104, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681938.40957}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=247.930540894 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_7deea5f8-669e-459c-b2fe-83bc3883eada-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.72113800048828, \"sum\": 57.72113800048828, \"min\": 57.72113800048828}}, \"EndTime\": 1551681941.069282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681941.011135}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:41 INFO 140211577685824] Epoch[39] Batch[0] avg_epoch_loss=4.545270\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:42 INFO 140211577685824] Epoch[39] Batch[5] avg_epoch_loss=4.524396\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:42 INFO 140211577685824] Epoch[39] Batch [5]#011Speed: 298.65 samples/sec#011loss=4.524396\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:43 INFO 140211577685824] processed a total of 615 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2381.5579414367676, \"sum\": 2381.5579414367676, \"min\": 2381.5579414367676}}, \"EndTime\": 1551681943.450989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681941.06936}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:43 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=258.219121832 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:43 INFO 140211577685824] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:43 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:43 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_dc067961-5177-4a1c-8452-5b3d89fdd855-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 58.05206298828125, \"sum\": 58.05206298828125, \"min\": 58.05206298828125}}, \"EndTime\": 1551681943.509484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681943.451085}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:43 INFO 140211577685824] Epoch[40] Batch[0] avg_epoch_loss=4.569825\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:45 INFO 140211577685824] Epoch[40] Batch[5] avg_epoch_loss=4.535739\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:45 INFO 140211577685824] Epoch[40] Batch [5]#011Speed: 303.58 samples/sec#011loss=4.535739\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] Epoch[40] Batch[10] avg_epoch_loss=4.526386\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] Epoch[40] Batch [10]#011Speed: 302.35 samples/sec#011loss=4.515164\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] processed a total of 702 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2583.35018157959, \"sum\": 2583.35018157959, \"min\": 2583.35018157959}}, \"EndTime\": 1551681946.092957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681943.509542}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=271.727875055 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_9a2f13bd-1a3e-4802-9827-9d4fc4ab3ade-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.70087242126465, \"sum\": 57.70087242126465, \"min\": 57.70087242126465}}, \"EndTime\": 1551681946.151136, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681946.093031}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:46 INFO 140211577685824] Epoch[41] Batch[0] avg_epoch_loss=4.557332\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:47 INFO 140211577685824] Epoch[41] Batch[5] avg_epoch_loss=4.511800\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:47 INFO 140211577685824] Epoch[41] Batch [5]#011Speed: 293.55 samples/sec#011loss=4.511800\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:48 INFO 140211577685824] processed a total of 612 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2392.5719261169434, \"sum\": 2392.5719261169434, \"min\": 2392.5719261169434}}, \"EndTime\": 1551681948.543857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681946.151212}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:48 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=255.777995998 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:48 INFO 140211577685824] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:48 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:48 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_9a9389c8-83cc-4dab-8524-bea3a6a1e151-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.84591484069824, \"sum\": 69.84591484069824, \"min\": 69.84591484069824}}, \"EndTime\": 1551681948.614172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681948.543942}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:49 INFO 140211577685824] Epoch[42] Batch[0] avg_epoch_loss=4.504163\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:50 INFO 140211577685824] Epoch[42] Batch[5] avg_epoch_loss=4.487942\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:50 INFO 140211577685824] Epoch[42] Batch [5]#011Speed: 308.46 samples/sec#011loss=4.487942\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:50 INFO 140211577685824] processed a total of 626 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2349.846124649048, \"sum\": 2349.846124649048, \"min\": 2349.846124649048}}, \"EndTime\": 1551681950.964151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681948.614243}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:50 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=266.386043485 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:50 INFO 140211577685824] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:50 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:51 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_37d4c725-acb7-46e0-a5f0-b0ad40824804-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 82.64708518981934, \"sum\": 82.64708518981934, \"min\": 82.64708518981934}}, \"EndTime\": 1551681951.047271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681950.964237}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:51 INFO 140211577685824] Epoch[43] Batch[0] avg_epoch_loss=4.506304\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:52 INFO 140211577685824] Epoch[43] Batch[5] avg_epoch_loss=4.471238\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:52 INFO 140211577685824] Epoch[43] Batch [5]#011Speed: 299.48 samples/sec#011loss=4.471238\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] Epoch[43] Batch[10] avg_epoch_loss=4.449795\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] Epoch[43] Batch [10]#011Speed: 294.94 samples/sec#011loss=4.424064\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] processed a total of 659 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2614.593029022217, \"sum\": 2614.593029022217, \"min\": 2614.593029022217}}, \"EndTime\": 1551681953.66201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681951.047344}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=252.03522197 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:53 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_ef39560d-e53d-4c9b-9600-279d06b783e5-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 58.02798271179199, \"sum\": 58.02798271179199, \"min\": 58.02798271179199}}, \"EndTime\": 1551681953.720528, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681953.662088}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:54 INFO 140211577685824] Epoch[44] Batch[0] avg_epoch_loss=4.603788\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:55 INFO 140211577685824] Epoch[44] Batch[5] avg_epoch_loss=4.521464\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:55 INFO 140211577685824] Epoch[44] Batch [5]#011Speed: 303.90 samples/sec#011loss=4.521464\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:45:56 INFO 140211577685824] processed a total of 624 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2364.4251823425293, \"sum\": 2364.4251823425293, \"min\": 2364.4251823425293}}, \"EndTime\": 1551681956.085298, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681953.720801}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:56 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=263.898326505 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:56 INFO 140211577685824] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:56 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:56 INFO 140211577685824] Epoch[45] Batch[0] avg_epoch_loss=4.483387\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:57 INFO 140211577685824] Epoch[45] Batch[5] avg_epoch_loss=4.449368\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:57 INFO 140211577685824] Epoch[45] Batch [5]#011Speed: 281.37 samples/sec#011loss=4.449368\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:58 INFO 140211577685824] Epoch[45] Batch[10] avg_epoch_loss=4.451098\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:58 INFO 140211577685824] Epoch[45] Batch [10]#011Speed: 296.72 samples/sec#011loss=4.453174\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:58 INFO 140211577685824] processed a total of 663 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2675.3859519958496, \"sum\": 2675.3859519958496, \"min\": 2675.3859519958496}}, \"EndTime\": 1551681958.761128, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681956.085374}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:58 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=247.804333188 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:58 INFO 140211577685824] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:58 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:45:59 INFO 140211577685824] Epoch[46] Batch[0] avg_epoch_loss=4.659582\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:00 INFO 140211577685824] Epoch[46] Batch[5] avg_epoch_loss=4.497471\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:00 INFO 140211577685824] Epoch[46] Batch [5]#011Speed: 297.17 samples/sec#011loss=4.497471\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:01 INFO 140211577685824] processed a total of 583 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2404.5159816741943, \"sum\": 2404.5159816741943, \"min\": 2404.5159816741943}}, \"EndTime\": 1551681961.166072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681958.761197}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:01 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=242.447529439 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:01 INFO 140211577685824] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:01 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:01 INFO 140211577685824] Epoch[47] Batch[0] avg_epoch_loss=4.469697\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:02 INFO 140211577685824] Epoch[47] Batch[5] avg_epoch_loss=4.429368\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:02 INFO 140211577685824] Epoch[47] Batch [5]#011Speed: 294.06 samples/sec#011loss=4.429368\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] Epoch[47] Batch[10] avg_epoch_loss=4.443358\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] Epoch[47] Batch [10]#011Speed: 291.33 samples/sec#011loss=4.460146\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] processed a total of 650 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2648.9298343658447, \"sum\": 2648.9298343658447, \"min\": 2648.9298343658447}}, \"EndTime\": 1551681963.815457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681961.166158}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=245.370695209 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:03 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_361c59fc-e3a0-45ba-8a1c-23f511c276a7-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 74.28193092346191, \"sum\": 74.28193092346191, \"min\": 74.28193092346191}}, \"EndTime\": 1551681963.890198, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681963.81554}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:04 INFO 140211577685824] Epoch[48] Batch[0] avg_epoch_loss=4.470158\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:05 INFO 140211577685824] Epoch[48] Batch[5] avg_epoch_loss=4.443818\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:05 INFO 140211577685824] Epoch[48] Batch [5]#011Speed: 303.45 samples/sec#011loss=4.443818\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] Epoch[48] Batch[10] avg_epoch_loss=4.430504\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] Epoch[48] Batch [10]#011Speed: 290.37 samples/sec#011loss=4.414527\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] processed a total of 664 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2624.680995941162, \"sum\": 2624.680995941162, \"min\": 2624.680995941162}}, \"EndTime\": 1551681966.515032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681963.89028}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=252.970509278 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:06 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_9ff9876e-9fd8-4b2a-8bea-7f135b4dde66-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 57.322025299072266, \"sum\": 57.322025299072266, \"min\": 57.322025299072266}}, \"EndTime\": 1551681966.572843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681966.515121}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:07 INFO 140211577685824] Epoch[49] Batch[0] avg_epoch_loss=4.364609\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:08 INFO 140211577685824] Epoch[49] Batch[5] avg_epoch_loss=4.436736\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:08 INFO 140211577685824] Epoch[49] Batch [5]#011Speed: 299.68 samples/sec#011loss=4.436736\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:08 INFO 140211577685824] processed a total of 607 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2426.3229370117188, \"sum\": 2426.3229370117188, \"min\": 2426.3229370117188}}, \"EndTime\": 1551681968.999317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681966.572919}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:08 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=250.158861144 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:08 INFO 140211577685824] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:08 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:09 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_1310d820-a1f8-4581-ae1f-d0aa687c5aa1-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 58.78090858459473, \"sum\": 58.78090858459473, \"min\": 58.78090858459473}}, \"EndTime\": 1551681969.058619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681968.999406}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:09 INFO 140211577685824] Epoch[50] Batch[0] avg_epoch_loss=4.576493\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:10 INFO 140211577685824] Epoch[50] Batch[5] avg_epoch_loss=4.457707\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:10 INFO 140211577685824] Epoch[50] Batch [5]#011Speed: 298.37 samples/sec#011loss=4.457707\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:11 INFO 140211577685824] Epoch[50] Batch[10] avg_epoch_loss=4.427737\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:11 INFO 140211577685824] Epoch[50] Batch [10]#011Speed: 297.19 samples/sec#011loss=4.391773\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:11 INFO 140211577685824] processed a total of 669 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2610.5799674987793, \"sum\": 2610.5799674987793, \"min\": 2610.5799674987793}}, \"EndTime\": 1551681971.669337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681969.058683}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:11 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=256.252116508 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:11 INFO 140211577685824] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:11 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:12 INFO 140211577685824] Epoch[51] Batch[0] avg_epoch_loss=4.422586\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:13 INFO 140211577685824] Epoch[51] Batch[5] avg_epoch_loss=4.422981\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:13 INFO 140211577685824] Epoch[51] Batch [5]#011Speed: 305.24 samples/sec#011loss=4.422981\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:14 INFO 140211577685824] processed a total of 622 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2391.615867614746, \"sum\": 2391.615867614746, \"min\": 2391.615867614746}}, \"EndTime\": 1551681974.061418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681971.669422}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:14 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=260.06115889 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:14 INFO 140211577685824] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:14 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:14 INFO 140211577685824] Epoch[52] Batch[0] avg_epoch_loss=4.432461\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:15 INFO 140211577685824] Epoch[52] Batch[5] avg_epoch_loss=4.405241\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:15 INFO 140211577685824] Epoch[52] Batch [5]#011Speed: 301.20 samples/sec#011loss=4.405241\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:16 INFO 140211577685824] processed a total of 613 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2411.6718769073486, \"sum\": 2411.6718769073486, \"min\": 2411.6718769073486}}, \"EndTime\": 1551681976.473555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681974.061506}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:16 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=254.166996793 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:16 INFO 140211577685824] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:16 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:16 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_1894d5f3-3478-4788-b10d-3662541caa2a-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 84.5041275024414, \"sum\": 84.5041275024414, \"min\": 84.5041275024414}}, \"EndTime\": 1551681976.558585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681976.473641}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:46:17 INFO 140211577685824] Epoch[53] Batch[0] avg_epoch_loss=4.333606\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:18 INFO 140211577685824] Epoch[53] Batch[5] avg_epoch_loss=4.392793\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:18 INFO 140211577685824] Epoch[53] Batch [5]#011Speed: 303.94 samples/sec#011loss=4.392793\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:18 INFO 140211577685824] processed a total of 608 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2381.026029586792, \"sum\": 2381.026029586792, \"min\": 2381.026029586792}}, \"EndTime\": 1551681978.939765, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681976.558667}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:18 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=255.336351748 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:18 INFO 140211577685824] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:18 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:19 INFO 140211577685824] Epoch[54] Batch[0] avg_epoch_loss=4.398321\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:20 INFO 140211577685824] Epoch[54] Batch[5] avg_epoch_loss=4.422224\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:20 INFO 140211577685824] Epoch[54] Batch [5]#011Speed: 301.94 samples/sec#011loss=4.422224\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:21 INFO 140211577685824] processed a total of 632 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2376.178026199341, \"sum\": 2376.178026199341, \"min\": 2376.178026199341}}, \"EndTime\": 1551681981.316389, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681978.939868}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:21 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=265.958473638 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:21 INFO 140211577685824] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:21 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:21 INFO 140211577685824] Epoch[55] Batch[0] avg_epoch_loss=4.321719\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:22 INFO 140211577685824] Epoch[55] Batch[5] avg_epoch_loss=4.374793\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:22 INFO 140211577685824] Epoch[55] Batch [5]#011Speed: 296.31 samples/sec#011loss=4.374793\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] Epoch[55] Batch[10] avg_epoch_loss=4.379209\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] Epoch[55] Batch [10]#011Speed: 297.42 samples/sec#011loss=4.384507\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] processed a total of 665 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2610.553979873657, \"sum\": 2610.553979873657, \"min\": 2610.553979873657}}, \"EndTime\": 1551681983.927406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681981.316478}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=254.723106724 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:23 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_e04c1a50-8bdf-49b4-9ff6-20433d1cd1b2-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 69.02694702148438, \"sum\": 69.02694702148438, \"min\": 69.02694702148438}}, \"EndTime\": 1551681983.996913, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681983.92749}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:24 INFO 140211577685824] Epoch[56] Batch[0] avg_epoch_loss=4.268834\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:25 INFO 140211577685824] Epoch[56] Batch[5] avg_epoch_loss=4.314862\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:25 INFO 140211577685824] Epoch[56] Batch [5]#011Speed: 300.63 samples/sec#011loss=4.314862\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] Epoch[56] Batch[10] avg_epoch_loss=4.322399\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] Epoch[56] Batch [10]#011Speed: 297.56 samples/sec#011loss=4.331444\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] processed a total of 674 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2600.548028945923, \"sum\": 2600.548028945923, \"min\": 2600.548028945923}}, \"EndTime\": 1551681986.59762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681983.997}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=259.165091455 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:26 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_4ebf76dd-bb86-4e2e-b74a-a6237b71774a-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.201955795288086, \"sum\": 59.201955795288086, \"min\": 59.201955795288086}}, \"EndTime\": 1551681986.6573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681986.597685}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:27 INFO 140211577685824] Epoch[57] Batch[0] avg_epoch_loss=4.352156\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:28 INFO 140211577685824] Epoch[57] Batch[5] avg_epoch_loss=4.327573\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:28 INFO 140211577685824] Epoch[57] Batch [5]#011Speed: 302.21 samples/sec#011loss=4.327573\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] Epoch[57] Batch[10] avg_epoch_loss=4.340720\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] Epoch[57] Batch [10]#011Speed: 294.60 samples/sec#011loss=4.356497\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] processed a total of 664 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2635.4079246520996, \"sum\": 2635.4079246520996, \"min\": 2635.4079246520996}}, \"EndTime\": 1551681989.292847, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681986.657376}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=251.941530038 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:29 INFO 140211577685824] Epoch[58] Batch[0] avg_epoch_loss=4.566897\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:30 INFO 140211577685824] Epoch[58] Batch[5] avg_epoch_loss=4.398227\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:30 INFO 140211577685824] Epoch[58] Batch [5]#011Speed: 302.51 samples/sec#011loss=4.398227\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:31 INFO 140211577685824] Epoch[58] Batch[10] avg_epoch_loss=4.382917\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:31 INFO 140211577685824] Epoch[58] Batch [10]#011Speed: 295.15 samples/sec#011loss=4.364544\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:31 INFO 140211577685824] processed a total of 653 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2602.107048034668, \"sum\": 2602.107048034668, \"min\": 2602.107048034668}}, \"EndTime\": 1551681991.895363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681989.292931}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:31 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=250.938611086 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:31 INFO 140211577685824] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:31 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:32 INFO 140211577685824] Epoch[59] Batch[0] avg_epoch_loss=4.405654\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:33 INFO 140211577685824] Epoch[59] Batch[5] avg_epoch_loss=4.351738\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:33 INFO 140211577685824] Epoch[59] Batch [5]#011Speed: 288.74 samples/sec#011loss=4.351738\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] Epoch[59] Batch[10] avg_epoch_loss=4.336313\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] Epoch[59] Batch [10]#011Speed: 293.40 samples/sec#011loss=4.317803\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] processed a total of 646 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2663.23184967041, \"sum\": 2663.23184967041, \"min\": 2663.23184967041}}, \"EndTime\": 1551681994.559007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681991.895445}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=242.548667725 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:34 INFO 140211577685824] Epoch[60] Batch[0] avg_epoch_loss=4.763312\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:36 INFO 140211577685824] Epoch[60] Batch[5] avg_epoch_loss=4.463393\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:36 INFO 140211577685824] Epoch[60] Batch [5]#011Speed: 298.19 samples/sec#011loss=4.463393\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:46:36 INFO 140211577685824] processed a total of 636 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2362.3180389404297, \"sum\": 2362.3180389404297, \"min\": 2362.3180389404297}}, \"EndTime\": 1551681996.921799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681994.559115}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:36 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=269.212630535 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:36 INFO 140211577685824] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:36 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:37 INFO 140211577685824] Epoch[61] Batch[0] avg_epoch_loss=4.306381\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:38 INFO 140211577685824] Epoch[61] Batch[5] avg_epoch_loss=4.310008\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:38 INFO 140211577685824] Epoch[61] Batch [5]#011Speed: 298.92 samples/sec#011loss=4.310008\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:39 INFO 140211577685824] processed a total of 566 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2175.973892211914, \"sum\": 2175.973892211914, \"min\": 2175.973892211914}}, \"EndTime\": 1551681999.098176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681996.921887}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:39 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=260.100618978 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:39 INFO 140211577685824] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:39 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:39 INFO 140211577685824] Epoch[62] Batch[0] avg_epoch_loss=4.316715\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:40 INFO 140211577685824] Epoch[62] Batch[5] avg_epoch_loss=4.303490\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:40 INFO 140211577685824] Epoch[62] Batch [5]#011Speed: 305.37 samples/sec#011loss=4.303490\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] Epoch[62] Batch[10] avg_epoch_loss=4.310653\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] Epoch[62] Batch [10]#011Speed: 289.30 samples/sec#011loss=4.319248\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] processed a total of 643 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2602.991819381714, \"sum\": 2602.991819381714, \"min\": 2602.991819381714}}, \"EndTime\": 1551682001.701593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551681999.098243}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=247.01242418 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:41 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_29b1a3e1-52a7-40ab-89ef-b00d3e1c9fc2-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 59.99016761779785, \"sum\": 59.99016761779785, \"min\": 59.99016761779785}}, \"EndTime\": 1551682001.762075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682001.70167}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:42 INFO 140211577685824] Epoch[63] Batch[0] avg_epoch_loss=4.401579\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:43 INFO 140211577685824] Epoch[63] Batch[5] avg_epoch_loss=4.376169\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:43 INFO 140211577685824] Epoch[63] Batch [5]#011Speed: 298.48 samples/sec#011loss=4.376169\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:44 INFO 140211577685824] processed a total of 633 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2388.1988525390625, \"sum\": 2388.1988525390625, \"min\": 2388.1988525390625}}, \"EndTime\": 1551682004.15041, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682001.76215}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:44 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=265.04052553 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:44 INFO 140211577685824] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:44 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:44 INFO 140211577685824] Epoch[64] Batch[0] avg_epoch_loss=4.288484\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:45 INFO 140211577685824] Epoch[64] Batch[5] avg_epoch_loss=4.311066\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:45 INFO 140211577685824] Epoch[64] Batch [5]#011Speed: 299.02 samples/sec#011loss=4.311066\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:46 INFO 140211577685824] processed a total of 637 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2366.0480976104736, \"sum\": 2366.0480976104736, \"min\": 2366.0480976104736}}, \"EndTime\": 1551682006.516876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682004.150482}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:46 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=269.2138212 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:46 INFO 140211577685824] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:46 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:46 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_037b0a51-b1ba-41c9-bbd8-c08cd96a80ca-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 60.305118560791016, \"sum\": 60.305118560791016, \"min\": 60.305118560791016}}, \"EndTime\": 1551682006.577608, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682006.516943}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:47 INFO 140211577685824] Epoch[65] Batch[0] avg_epoch_loss=4.343566\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:48 INFO 140211577685824] Epoch[65] Batch[5] avg_epoch_loss=4.291552\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:48 INFO 140211577685824] Epoch[65] Batch [5]#011Speed: 292.46 samples/sec#011loss=4.291552\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] Epoch[65] Batch[10] avg_epoch_loss=4.303208\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] Epoch[65] Batch [10]#011Speed: 300.62 samples/sec#011loss=4.317194\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] processed a total of 682 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2623.0411529541016, \"sum\": 2623.0411529541016, \"min\": 2623.0411529541016}}, \"EndTime\": 1551682009.200806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682006.577693}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=259.990879054 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:49 INFO 140211577685824] Epoch[66] Batch[0] avg_epoch_loss=4.332748\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:50 INFO 140211577685824] Epoch[66] Batch[5] avg_epoch_loss=4.333046\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:50 INFO 140211577685824] Epoch[66] Batch [5]#011Speed: 300.61 samples/sec#011loss=4.333046\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:51 INFO 140211577685824] Epoch[66] Batch[10] avg_epoch_loss=4.315959\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:51 INFO 140211577685824] Epoch[66] Batch [10]#011Speed: 300.83 samples/sec#011loss=4.295455\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:51 INFO 140211577685824] processed a total of 681 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2632.671117782593, \"sum\": 2632.671117782593, \"min\": 2632.671117782593}}, \"EndTime\": 1551682011.833879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682009.200891}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:51 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=258.660674431 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:51 INFO 140211577685824] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:51 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:52 INFO 140211577685824] Epoch[67] Batch[0] avg_epoch_loss=4.275058\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:53 INFO 140211577685824] Epoch[67] Batch[5] avg_epoch_loss=4.295482\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:53 INFO 140211577685824] Epoch[67] Batch [5]#011Speed: 303.88 samples/sec#011loss=4.295482\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] Epoch[67] Batch[10] avg_epoch_loss=4.299452\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] Epoch[67] Batch [10]#011Speed: 293.60 samples/sec#011loss=4.304216\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] processed a total of 644 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2647.249221801758, \"sum\": 2647.249221801758, \"min\": 2647.249221801758}}, \"EndTime\": 1551682014.481536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682011.833961}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=243.259823039 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:54 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_2a49166d-0cf1-4fb7-b290-637e3ae0c0e3-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 91.09210968017578, \"sum\": 91.09210968017578, \"min\": 91.09210968017578}}, \"EndTime\": 1551682014.573095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682014.481619}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:55 INFO 140211577685824] Epoch[68] Batch[0] avg_epoch_loss=4.334629\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:56 INFO 140211577685824] Epoch[68] Batch[5] avg_epoch_loss=4.286555\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:56 INFO 140211577685824] Epoch[68] Batch [5]#011Speed: 300.22 samples/sec#011loss=4.286555\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] Epoch[68] Batch[10] avg_epoch_loss=4.283849\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] Epoch[68] Batch [10]#011Speed: 294.06 samples/sec#011loss=4.280602\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] processed a total of 676 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2629.6801567077637, \"sum\": 2629.6801567077637, \"min\": 2629.6801567077637}}, \"EndTime\": 1551682017.202922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682014.573174}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=257.051709618 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_d771fab5-a642-46e7-a67d-a60b08007c33-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 61.68818473815918, \"sum\": 61.68818473815918, \"min\": 61.68818473815918}}, \"EndTime\": 1551682017.265163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682017.20302}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:57 INFO 140211577685824] Epoch[69] Batch[0] avg_epoch_loss=4.286968\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:58 INFO 140211577685824] Epoch[69] Batch[5] avg_epoch_loss=4.257515\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:58 INFO 140211577685824] Epoch[69] Batch [5]#011Speed: 288.99 samples/sec#011loss=4.257515\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:59 INFO 140211577685824] processed a total of 617 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2403.7997722625732, \"sum\": 2403.7997722625732, \"min\": 2403.7997722625732}}, \"EndTime\": 1551682019.669111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682017.265245}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:59 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=256.66432584 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:59 INFO 140211577685824] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:59 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:46:59 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_1f4a6d3d-2348-4971-998b-0c0997b95d68-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 67.2769546508789, \"sum\": 67.2769546508789, \"min\": 67.2769546508789}}, \"EndTime\": 1551682019.736838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682019.669193}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:00 INFO 140211577685824] Epoch[70] Batch[0] avg_epoch_loss=4.215421\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:01 INFO 140211577685824] Epoch[70] Batch[5] avg_epoch_loss=4.239604\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:01 INFO 140211577685824] Epoch[70] Batch [5]#011Speed: 295.36 samples/sec#011loss=4.239604\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:02 INFO 140211577685824] processed a total of 625 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2392.53306388855, \"sum\": 2392.53306388855, \"min\": 2392.53306388855}}, \"EndTime\": 1551682022.129501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682019.736909}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:02 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=261.215431385 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:02 INFO 140211577685824] #progress_metric: host=algo-1, completed 88 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:02 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:02 INFO 140211577685824] Epoch[71] Batch[0] avg_epoch_loss=4.239889\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:03 INFO 140211577685824] Epoch[71] Batch[5] avg_epoch_loss=4.232928\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:03 INFO 140211577685824] Epoch[71] Batch [5]#011Speed: 299.42 samples/sec#011loss=4.232928\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] Epoch[71] Batch[10] avg_epoch_loss=4.234829\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] Epoch[71] Batch [10]#011Speed: 293.56 samples/sec#011loss=4.237110\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] processed a total of 641 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2624.7689723968506, \"sum\": 2624.7689723968506, \"min\": 2624.7689723968506}}, \"EndTime\": 1551682024.754699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682022.129589}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=244.200434911 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:04 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_ac2e8cca-28c9-4852-a8e8-bec417fee238-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 62.52884864807129, \"sum\": 62.52884864807129, \"min\": 62.52884864807129}}, \"EndTime\": 1551682024.817773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682024.754781}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:05 INFO 140211577685824] Epoch[72] Batch[0] avg_epoch_loss=4.249170\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:06 INFO 140211577685824] Epoch[72] Batch[5] avg_epoch_loss=4.231510\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:06 INFO 140211577685824] Epoch[72] Batch [5]#011Speed: 294.00 samples/sec#011loss=4.231510\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:07 INFO 140211577685824] processed a total of 624 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2411.669969558716, \"sum\": 2411.669969558716, \"min\": 2411.669969558716}}, \"EndTime\": 1551682027.229586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682024.81785}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:07 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=258.729107485 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:07 INFO 140211577685824] #progress_metric: host=algo-1, completed 91 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:07 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:07 INFO 140211577685824] Epoch[73] Batch[0] avg_epoch_loss=4.214750\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:08 INFO 140211577685824] Epoch[73] Batch[5] avg_epoch_loss=4.208215\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:08 INFO 140211577685824] Epoch[73] Batch [5]#011Speed: 292.28 samples/sec#011loss=4.208215\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:09 INFO 140211577685824] processed a total of 636 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2415.0049686431885, \"sum\": 2415.0049686431885, \"min\": 2415.0049686431885}}, \"EndTime\": 1551682029.645025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682027.229667}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:09 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=263.339326601 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:09 INFO 140211577685824] #progress_metric: host=algo-1, completed 92 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:09 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:10 INFO 140211577685824] Epoch[74] Batch[0] avg_epoch_loss=4.225807\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:11 INFO 140211577685824] Epoch[74] Batch[5] avg_epoch_loss=4.246253\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:11 INFO 140211577685824] Epoch[74] Batch [5]#011Speed: 293.96 samples/sec#011loss=4.246253\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] Epoch[74] Batch[10] avg_epoch_loss=4.254647\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] Epoch[74] Batch [10]#011Speed: 299.41 samples/sec#011loss=4.264720\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] processed a total of 644 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2624.0878105163574, \"sum\": 2624.0878105163574, \"min\": 2624.0878105163574}}, \"EndTime\": 1551682032.269537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682029.645113}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=245.406910507 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:12 INFO 140211577685824] Epoch[75] Batch[0] avg_epoch_loss=4.214021\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:13 INFO 140211577685824] Epoch[75] Batch[5] avg_epoch_loss=4.248964\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:13 INFO 140211577685824] Epoch[75] Batch [5]#011Speed: 293.52 samples/sec#011loss=4.248964\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:14 INFO 140211577685824] processed a total of 632 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2412.6861095428467, \"sum\": 2412.6861095428467, \"min\": 2412.6861095428467}}, \"EndTime\": 1551682034.682634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682032.269619}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:14 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=261.934597381 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:14 INFO 140211577685824] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:14 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:15 INFO 140211577685824] Epoch[76] Batch[0] avg_epoch_loss=4.239969\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:16 INFO 140211577685824] Epoch[76] Batch[5] avg_epoch_loss=4.272247\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:16 INFO 140211577685824] Epoch[76] Batch [5]#011Speed: 302.82 samples/sec#011loss=4.272247\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[03/04/2019 06:47:17 INFO 140211577685824] processed a total of 611 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2392.302989959717, \"sum\": 2392.302989959717, \"min\": 2392.302989959717}}, \"EndTime\": 1551682037.075362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682034.682722}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:17 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=255.388865243 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:17 INFO 140211577685824] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:17 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:17 INFO 140211577685824] Epoch[77] Batch[0] avg_epoch_loss=4.285887\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:18 INFO 140211577685824] Epoch[77] Batch[5] avg_epoch_loss=4.256684\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:18 INFO 140211577685824] Epoch[77] Batch [5]#011Speed: 300.24 samples/sec#011loss=4.256684\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:19 INFO 140211577685824] Epoch[77] Batch[10] avg_epoch_loss=4.255090\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:19 INFO 140211577685824] Epoch[77] Batch [10]#011Speed: 282.22 samples/sec#011loss=4.253177\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:19 INFO 140211577685824] processed a total of 672 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2716.5780067443848, \"sum\": 2716.5780067443848, \"min\": 2716.5780067443848}}, \"EndTime\": 1551682039.792349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682037.075448}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:19 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=247.358573763 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:19 INFO 140211577685824] #progress_metric: host=algo-1, completed 97 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:19 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:20 INFO 140211577685824] Epoch[78] Batch[0] avg_epoch_loss=4.231659\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:21 INFO 140211577685824] Epoch[78] Batch[5] avg_epoch_loss=4.194431\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:21 INFO 140211577685824] Epoch[78] Batch [5]#011Speed: 292.55 samples/sec#011loss=4.194431\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] Epoch[78] Batch[10] avg_epoch_loss=4.200016\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] Epoch[78] Batch [10]#011Speed: 299.78 samples/sec#011loss=4.206717\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] processed a total of 658 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2638.240098953247, \"sum\": 2638.240098953247, \"min\": 2638.240098953247}}, \"EndTime\": 1551682042.431002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682039.792432}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=249.39347436 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] #progress_metric: host=algo-1, completed 98 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] best epoch loss so far\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/state_b710a496-82f2-4795-9d2e-7fdc2b2f3b96-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 83.97388458251953, \"sum\": 83.97388458251953, \"min\": 83.97388458251953}}, \"EndTime\": 1551682042.515502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682042.431122}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:22 INFO 140211577685824] Epoch[79] Batch[0] avg_epoch_loss=4.187037\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:24 INFO 140211577685824] Epoch[79] Batch[5] avg_epoch_loss=4.231392\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:24 INFO 140211577685824] Epoch[79] Batch [5]#011Speed: 299.47 samples/sec#011loss=4.231392\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] Epoch[79] Batch[10] avg_epoch_loss=4.203881\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] Epoch[79] Batch [10]#011Speed: 296.98 samples/sec#011loss=4.170869\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] processed a total of 649 examples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 2598.0899333953857, \"sum\": 2598.0899333953857, \"min\": 2598.0899333953857}}, \"EndTime\": 1551682045.113731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682042.515577}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] #throughput_metric: host=algo-1, train throughput=249.788398714 records/second\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] loss did not improve\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] Final loss: 4.20001550154 (occurred at epoch 78)\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] #quality_metric: host=algo-1, train final_loss <loss>=4.20001550154\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 WARNING 140211577685824] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:25 INFO 140211577685824] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2443.419933319092, \"sum\": 2443.419933319092, \"min\": 2443.419933319092}}, \"EndTime\": 1551682047.558036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682045.113798}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:27 INFO 140211577685824] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 2698.8871097564697, \"sum\": 2698.8871097564697, \"min\": 2698.8871097564697}}, \"EndTime\": 1551682047.813465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682047.558128}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:27 INFO 140211577685824] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:27 INFO 140211577685824] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 38.39993476867676, \"sum\": 38.39993476867676, \"min\": 38.39993476867676}}, \"EndTime\": 1551682047.851998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682047.813549}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:27 INFO 140211577685824] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:27 INFO 140211577685824] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.030040740966796875, \"sum\": 0.030040740966796875, \"min\": 0.030040740966796875}}, \"EndTime\": 1551682047.85282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682047.852053}\n",
      "\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 3255.829095840454, \"sum\": 3255.829095840454, \"min\": 3255.829095840454}}, \"EndTime\": 1551682051.10863, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682047.852871}\n",
      "\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, RMSE): 123.920892893\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, mean_wQuantileLoss): 0.114477\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.1]): 0.0305831\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.2]): 0.0569567\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.3]): 0.0810444\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.4]): 0.103235\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.5]): 0.123352\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.6]): 0.141278\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.7]): 0.1564\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.8]): 0.167711\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #test_score (algo-1, wQuantileLoss[0.9]): 0.169735\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #quality_metric: host=algo-1, test RMSE <loss>=123.920892893\u001b[0m\n",
      "\u001b[31m[03/04/2019 06:47:31 INFO 140211577685824] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.114477247\u001b[0m\n",
      "\u001b[31m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 213841.91489219666, \"sum\": 213841.91489219666, \"min\": 213841.91489219666}, \"setuptime\": {\"count\": 1, \"max\": 8.78286361694336, \"sum\": 8.78286361694336, \"min\": 8.78286361694336}}, \"EndTime\": 1551682051.187842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1551682051.10872}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-03-04 06:47:44 Uploading - Uploading generated training model\n",
      "2019-03-04 06:47:44 Completed - Training job completed\n",
      "Billable seconds: 271\n",
      "CPU times: user 860 ms, sys: 42.4 ms, total: 903 ms\n",
      "Wall time: 6min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/test/\".format(s3_data_path)\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測できるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        prediction_time = ts.index[-1] + 1\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルをデプロイして DeepARPredictor のエンドポイントを使えるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: forecasting-deepar-2019-03-04-06-48-11-168\n",
      "INFO:sagemaker:Creating endpoint with name deepar-electricity-demo-2019-03-04-06-41-26-931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測結果を確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-01 00:00:00</th>\n",
       "      <td>511.417664</td>\n",
       "      <td>532.092468</td>\n",
       "      <td>549.060242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 02:00:00</th>\n",
       "      <td>547.008362</td>\n",
       "      <td>563.693176</td>\n",
       "      <td>581.125305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 04:00:00</th>\n",
       "      <td>564.375610</td>\n",
       "      <td>580.388000</td>\n",
       "      <td>600.358948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 06:00:00</th>\n",
       "      <td>558.143616</td>\n",
       "      <td>574.080322</td>\n",
       "      <td>595.913147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01 08:00:00</th>\n",
       "      <td>552.872925</td>\n",
       "      <td>571.500427</td>\n",
       "      <td>592.141418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.1         0.5         0.9\n",
       "2018-04-01 00:00:00  511.417664  532.092468  549.060242\n",
       "2018-04-01 02:00:00  547.008362  563.693176  581.125305\n",
       "2018-04-01 04:00:00  564.375610  580.388000  600.358948\n",
       "2018-04-01 06:00:00  558.143616  574.080322  595.913147\n",
       "2018-04-01 08:00:00  552.872925  571.500427  592.141418"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(ts=timeseries[0], quantiles=[0.10, 0.5, 0.90]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    predictor, \n",
    "    target_ts, \n",
    "    cat=None, \n",
    "    dynamic_feat=None, \n",
    "    forecast_date=end_training, \n",
    "    show_samples=False, \n",
    "    plot_history=7 * 12,\n",
    "    confidence=80\n",
    "):\n",
    "    print(\"calling served model to generate predictions starting from {}\".format(str(forecast_date)))\n",
    "    assert(confidence > 50 and confidence < 100)\n",
    "    low_quantile = 0.5 - confidence * 0.005\n",
    "    up_quantile = confidence * 0.005 + 0.5\n",
    "        \n",
    "    args = {\n",
    "        \"ts\": target_ts[:forecast_date],\n",
    "        \"return_samples\": show_samples,\n",
    "        \"quantiles\": [low_quantile, 0.5, up_quantile],\n",
    "        \"num_samples\": 100\n",
    "    }\n",
    "\n",
    "\n",
    "    if dynamic_feat is not None:\n",
    "        args[\"dynamic_feat\"] = dynamic_feat\n",
    "        fig = plt.figure(figsize=(20, 6))\n",
    "        ax = plt.subplot(2, 1, 1)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(20, 3))\n",
    "        ax = plt.subplot(1,1,1)\n",
    "    \n",
    "    if cat is not None:\n",
    "        args[\"cat\"] = cat\n",
    "        ax.text(0.9, 0.9, 'cat = {}'.format(cat), transform=ax.transAxes)\n",
    "\n",
    "    prediction = predictor.predict(**args)\n",
    "\n",
    "    if show_samples: \n",
    "        for key in prediction.keys():\n",
    "            if \"sample\" in key:\n",
    "                prediction[key].plot(color='lightskyblue', alpha=0.2, label='_nolegend_')\n",
    "                \n",
    "    target_section = target_ts[forecast_date-plot_history:forecast_date+prediction_length]\n",
    "    target_section.plot(color=\"black\", label='target')\n",
    "    \n",
    "    ax.fill_between(\n",
    "        prediction[str(low_quantile)].index, \n",
    "        prediction[str(low_quantile)].values, \n",
    "        prediction[str(up_quantile)].values, \n",
    "        color=\"b\", alpha=0.3, label='{}% confidence interval'.format(confidence)\n",
    "    )\n",
    "    prediction[\"0.5\"].plot(color=\"b\", label='P50')\n",
    "    ax.legend(loc=2)    \n",
    "    \n",
    "    ax.set_ylim(target_section.min() * 0.5, target_section.max() * 1.5)\n",
    "    \n",
    "    if dynamic_feat is not None:\n",
    "        for i, f in enumerate(dynamic_feat, start=1):\n",
    "            ax = plt.subplot(len(dynamic_feat) * 2, 1, len(dynamic_feat) + i, sharex=ax)\n",
    "            feat_ts = pd.Series(\n",
    "                index=pd.DatetimeIndex(start=target_ts.index[0], freq=target_ts.index.freq, periods=len(f)),\n",
    "                data=f\n",
    "            )\n",
    "            feat_ts[forecast_date-plot_history:forecast_date+prediction_length].plot(ax=ax, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fe4626ca5145f4aae917f4cd7e1e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=51, description='forecast_day', style=SliderStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(\n",
    "    forecast_day=IntSlider(min=0, max=100, value=51, style=style),\n",
    "    confidence=IntSlider(min=60, max=95, value=80, step=5, style=style),\n",
    "    history_weeks_plot=IntSlider(min=1, max=20, value=1, style=style),\n",
    "    show_samples=Checkbox(value=False),\n",
    "    continuous_update=False\n",
    ")\n",
    "def plot_interact(forecast_day, confidence, history_weeks_plot, show_samples):\n",
    "    plot(\n",
    "        predictor,\n",
    "        target_ts=timeseries[0],\n",
    "        forecast_date=end_training + datetime.timedelta(days=forecast_day),\n",
    "        show_samples=show_samples,\n",
    "        plot_history=history_weeks_plot * 12 * 7,\n",
    "        confidence=confidence\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### このままデプロイしたままだと課金対象になるのでエンドポイントを削除する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
